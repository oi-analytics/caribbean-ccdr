{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd179058-23e5-4aa2-99b2-8d3d5f8cda5a",
   "metadata": {},
   "source": [
    "# Process FATHOM flooding\n",
    "\n",
    "- current pluvial and fluvial - read and rewrite with zeros over nodata/999 values\n",
    "\n",
    "- future pluvial and fluvial: apply change factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be79c9-2f30-4685-90e7-b3cecc04833b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973fcfd6-e992-4466-bf5d-e953791fcc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to incoming_data, storm surge data folder\n",
    "os.chdir(\"../../incoming_data/FATHOM Flood\")\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4eea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"../../processed_data/hazards/fathom_pluvial_fluvial/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34250990",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {out_dir}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd4ece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of return periods in data, plus artificial lower/upper bound\n",
    "RPS = np.array([0, 5, 10, 20, 50, 75, 100, 200, 250, 500, 1000, 1e6])\n",
    "# change factors available for [5, 10, 50, 100]\n",
    "\n",
    "\n",
    "def read_rp_map(fname):\n",
    "    \"\"\"Read flood map, use all cells with any depth > 0 as potential exposure\n",
    "    points\n",
    "    \"\"\"\n",
    "    with rasterio.open(fname) as dataset:\n",
    "        data = dataset.read(1)\n",
    "        data[data > 990] = 0\n",
    "        data[data < 0] = 0\n",
    "        data[data == dataset.nodata] = 0\n",
    "        np.nan_to_num(data, copy=False)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_transform(fname):\n",
    "    with rasterio.open(fname) as dataset:\n",
    "        crs = dataset.crs\n",
    "        ncols = dataset.width\n",
    "        nrows = dataset.height\n",
    "        transform = dataset.transform\n",
    "        nodata = dataset.nodata\n",
    "    return crs, ncols, nrows, transform, nodata\n",
    "\n",
    "\n",
    "def read_rp_maps(fnames, rps):\n",
    "    rp_data = {}\n",
    "    # Read the rest\n",
    "    for fname, rp in zip(fnames, rps):\n",
    "        rp_data[rp] = read_rp_map(fname)\n",
    "\n",
    "    return rp_data\n",
    "\n",
    "\n",
    "def save_to_tif(data, fname, nrows, ncols, crs, transform):\n",
    "    with rasterio.open(\n",
    "        fname,\n",
    "        \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=nrows,\n",
    "        width=ncols,\n",
    "        count=1,\n",
    "        dtype=data.dtype,\n",
    "        crs=crs,\n",
    "        transform=transform,\n",
    "        compress=\"lzw\",\n",
    "    ) as dataset:\n",
    "        dataset.write(data, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf70c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in tqdm(list(sorted(glob(\"**/*.tif\", recursive=True)))):\n",
    "    f = pathlib.Path(f)\n",
    "\n",
    "    country_name, hazard = f.parent.parts\n",
    "\n",
    "    match country_name:\n",
    "        case \"Dominica\":\n",
    "            isoa3 = \"dma\"\n",
    "        case \"St Vincent and the Grenadines\":\n",
    "            isoa3 = \"vct\"\n",
    "        case \"St Lucia\":\n",
    "            isoa3 = \"lca\"\n",
    "        case \"Grenada\":\n",
    "            isoa3 = \"grd\"\n",
    "\n",
    "    hazard_short, rp = re.match(r\"(\\w+)_1in(\\d+).tif\", f.name).group(1, 2)\n",
    "\n",
    "    epoch = \"2010\"\n",
    "    rcp = \"baseline\"\n",
    "    out_fname = f\"{hazard}__epoch_{epoch}__rcp_{rcp}__precipitation-factor_none__stat_none__rp_{rp}__isoa3_{isoa3}.tif\"\n",
    "\n",
    "    with rasterio.open(f) as dataset:\n",
    "        crs = dataset.crs\n",
    "        ncols = dataset.width\n",
    "        nrows = dataset.height\n",
    "        transform = dataset.transform\n",
    "        nodata = dataset.nodata\n",
    "    data = read_rp_map(f)\n",
    "    save_to_tif(data, os.path.join(out_dir, out_fname), nrows, ncols, crs, transform)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b274e40",
   "metadata": {},
   "source": [
    "## Apply change factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb62601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = ['p10', 'median', 'p90']  # median, p10, p90\n",
    "ssps = [\"ssp126\", \"ssp245\", \"ssp585\"]\n",
    "epochs = [2030, 2050]\n",
    "predict_rps = [\n",
    "    5,\n",
    "    10,\n",
    "    50,\n",
    "    100,\n",
    "]  # skip 25 as no correspondance to data, skip 20 as no equivalent in storm surge\n",
    "variables = [\"rx1day\", \"rx5day\", \"rxmonth\"]\n",
    "\n",
    "change_factors = pd.read_csv(\"../wbcckp/summary.csv\")\n",
    "change_factors[\"rp\"] = change_factors.calculation.str.extract(r\"(\\d+)\").astype(int)\n",
    "change_factors[\"rp_future\"] = change_factors.rp * change_factors.value\n",
    "\n",
    "\n",
    "def rename_epoch(epoch):\n",
    "    match epoch:\n",
    "        case \"2010-2039\":\n",
    "            epoch = 2030\n",
    "        case \"2035-2064\":\n",
    "            epoch = 2050\n",
    "        case \"2060-2089\":\n",
    "            epoch = 2070\n",
    "        case \"2070-2099\":\n",
    "            epoch = 2080\n",
    "    return epoch\n",
    "\n",
    "\n",
    "change_factors.epoch = change_factors.epoch.apply(rename_epoch)\n",
    "\n",
    "# copy full DataFrame for later exploration\n",
    "cf = change_factors.copy()\n",
    "\n",
    "# for col in change_factors.columns:\n",
    "#     print(col, \"\\n\", np.sort(change_factors[col].unique()), \"\\n\")\n",
    "\n",
    "change_factors = change_factors.query(\n",
    "    f\"ssp in {ssps} and epoch in {epochs} and rp in {predict_rps} and statistic in {statistics}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27a275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.query(\n",
    "    'ssp == \"ssp245\" and isoa3 == \"VCT\" and rp == 100 and epoch == 2050'\n",
    ")#[['variable', 'statistic', 'rp', 'rp_future']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0feb18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_factors.query(\n",
    "    'variable == \"rx1day\" and ssp == \"ssp245\" and isoa3 == \"VCT\" '\n",
    ").sort_values(by=[\"epoch\", \"rp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbbcdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_future_lookup = change_factors.set_index(\n",
    "    [\"isoa3\", \"statistic\", \"variable\", \"ssp\", \"epoch\", \"rp\"]\n",
    ")[\"rp_future\"].sort_index()\n",
    "rp_future_lookup[\"VCT\", \"median\", \"rx1day\", \"ssp126\", 2050]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1565e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_rp_factor(rp, rp_l, rp_u):\n",
    "    return (np.log(rp) - np.log(rp_l)) / (np.log(rp_u) - np.log(rp_l))\n",
    "\n",
    "\n",
    "def interpolate_depth(depth_l, depth_u, rp_factor):\n",
    "    return depth_l + ((depth_u - depth_l) * rp_factor)\n",
    "\n",
    "\n",
    "for isoa3, hazard in tqdm(list(itertools.product(\n",
    "    (\"vct\", \"dma\", \"grd\", \"lca\"), (\"fluvial_undefended\", \"fluvial_defended\", \"pluvial\")\n",
    "))):\n",
    "    if \"fluvial\" in hazard and isoa3 == \"vct\":\n",
    "        # no data\n",
    "        continue\n",
    "    # Read baseline depths\n",
    "    baseline_rps = (5, 10, 20, 50, 75, 100, 200, 250, 500, 1000)\n",
    "    fnames = [\n",
    "        f\"../../processed_data/hazards/fathom_pluvial_fluvial/{hazard}__epoch_2010__rcp_baseline__precipitation-factor_none__stat_none__rp_{baseline_rp}__isoa3_{isoa3}.tif\"\n",
    "        for baseline_rp in baseline_rps\n",
    "    ]\n",
    "    rp_depths = read_rp_maps(fnames, baseline_rps)\n",
    "    rp_depths[0] = np.zeros_like(rp_depths[5])\n",
    "    crs, ncols, nrows, transform, nodata = read_transform(fnames[0])\n",
    "\n",
    "    # Predict\n",
    "    for stat, var, ssp, epoch, rp in itertools.product(statistics, variables, ssps, epochs, predict_rps):\n",
    "        rp_future = rp_future_lookup[isoa3.upper(), stat, var, ssp, epoch, rp]\n",
    "        #print(isoa3, stat, var, ssp, epoch, rp, rp_future)\n",
    "        out_fname = (\n",
    "            \"../../processed_data/hazards/fathom_pluvial_fluvial/\"\n",
    "            f\"{hazard}__epoch_{epoch}__rcp_{ssp}__precipitation-factor_{var}__stat_{stat}__rp_{rp}__isoa3_{isoa3}.tif\"\n",
    "        )\n",
    "        rp_u_idx = np.searchsorted(RPS, rp_future, side=\"left\")\n",
    "        rp_l, rp_u = RPS[rp_u_idx - 1], RPS[rp_u_idx]\n",
    "        rp_factor = interpolate_rp_factor(rp_future, rp_l, rp_u)\n",
    "        depth_l = rp_depths[rp_l]\n",
    "        depth_u = rp_depths[rp_u]\n",
    "        depth_future = interpolate_depth(depth_l, depth_u, rp_factor)\n",
    "\n",
    "        save_to_tif(depth_future, out_fname, nrows, ncols, crs, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83abed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flooded_volume = []\n",
    "\n",
    "for isoa3, hazard in tqdm(list(itertools.product(\n",
    "    (\"vct\", \"dma\", \"grd\", \"lca\"), (\"fluvial_undefended\", \"fluvial_defended\", \"pluvial\")\n",
    "))):\n",
    "    if \"fluvial\" in hazard and isoa3 == \"vct\":\n",
    "        # no data\n",
    "        continue\n",
    "    baseline_rps = (5, 10, 20, 50, 75, 100, 200, 250, 500, 1000)\n",
    "    for rp in baseline_rps:\n",
    "        fname = (\n",
    "            \"../../processed_data/hazards/fathom_pluvial_fluvial/\"\n",
    "            f\"{hazard}__epoch_2010__rcp_baseline__precipitation-factor_none__stat_none__rp_{rp}__isoa3_{isoa3}.tif\"\n",
    "        )\n",
    "        data = read_rp_map(fname)\n",
    "        flooded_volume.append({\n",
    "            \"hazard\": hazard,\n",
    "            \"epoch\": 2010,\n",
    "            \"rcp\": \"baseline\",\n",
    "            \"precipitation-factor\": \"none\",\n",
    "            \"stat\": \"none\",\n",
    "            \"rp\": rp,\n",
    "            \"isoa3\": isoa3,\n",
    "            \"pixel_nonzero_count\": np.count_nonzero(data),\n",
    "            \"pixel_sum\": data.sum(),\n",
    "        })\n",
    "\n",
    "    for stat, var, ssp, epoch, rp in itertools.product(statistics, variables, ssps, epochs, predict_rps):\n",
    "        fname = (\n",
    "            \"../../processed_data/hazards/fathom_pluvial_fluvial/\"\n",
    "            f\"{hazard}__epoch_{epoch}__rcp_{ssp}__precipitation-factor_{var}__stat_{stat}__rp_{rp}__isoa3_{isoa3}.tif\"\n",
    "        )\n",
    "        data = read_rp_map(fname).flatten()\n",
    "\n",
    "        flooded_volume.append({\n",
    "            \"hazard\": hazard,\n",
    "            \"epoch\": epoch,\n",
    "            \"rcp\": ssp,\n",
    "            \"precipitation-factor\": var,\n",
    "            \"stat\": stat,\n",
    "            \"rp\": rp,\n",
    "            \"isoa3\": isoa3,\n",
    "            \"pixel_nonzero_count\": np.count_nonzero(data),\n",
    "            \"pixel_sum\": data.sum(),\n",
    "        })\n",
    "\n",
    "flooded_volume = pd.DataFrame(flooded_volume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b71ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flooded_volume \\\n",
    "    .to_csv(\"../../processed_data/hazards/fathom_pluvial_fluvial/depth_comparison.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97078e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rp_future_lookup) \\\n",
    "    .rename(columns={\"rp_future\": \"rp_present_equivalent\"}) \\\n",
    "    .to_csv(\"../../processed_data/hazards/fathom_pluvial_fluvial/rp_comparison.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45dcf3ab",
   "metadata": {},
   "source": [
    "## Explore change factor values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6207dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.epoch = pd.to_datetime(cf.epoch, format=\"%Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61465389",
   "metadata": {},
   "outputs": [],
   "source": [
    "for isoa3 in [\"VCT\", \"DMA\", \"GRD\", \"LCA\"]:\n",
    "    df = cf.query(\n",
    "        f'ssp==\"ssp245\" and isoa3 == \"{isoa3}\" and calculation == \"changefactorfaep100yr\" and statistic == \"p90\"'\n",
    "    ).pivot(index=\"epoch\", columns=\"variable\", values=\"value\").plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd480b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in [\"rx1day\", \"rx5day\", \"rxmonth\"]:\n",
    "    cf.query(\n",
    "        f'isoa3 == \"VCT\" and calculation == \"changefactorfaep100yr\" and variable == \"{variable}\" and statistic == \"p90\"'\n",
    "    ).pivot(index=\"epoch\", columns=\"ssp\", values=\"value\").plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838bd8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stat in (\"p90\", \"median\", \"p10\"):\n",
    "    cf.query(f'isoa3 == \"VCT\" and ssp == \"ssp245\" and variable == \"rx5day\" and statistic == \"{stat}\"').pivot(\n",
    "        index=\"epoch\", columns=\"rp\", values=\"value\"\n",
    "    ).plot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
